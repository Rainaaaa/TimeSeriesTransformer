{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import preprocess as p\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "from train import trainer, tester, priorityChecker, predict\n",
    "from dataset import CharData\n",
    "from modules import FinTransformer\n",
    "from encoder import EncFinTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In rank normalize\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 780/780 [07:56<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In joinrets\n",
      "(3786027, 101)\n"
     ]
    }
   ],
   "source": [
    "data = CharData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Loaders\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 214/214 [00:01<00:00, 124.22it/s]\n",
      "100%|██████████| 144/144 [00:02<00:00, 64.63it/s]\n",
      "100%|██████████| 359/359 [00:07<00:00, 49.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the datasets - \n",
      "Building the Loaders - \n"
     ]
    }
   ],
   "source": [
    "data.loaders(batch_size=8192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\FinTransformers\\v1.1-prev\\predict.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/FinTransformers/v1.1-prev/predict.ipynb#X30sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m data\u001b[39m.\u001b[39mdf\u001b[39m.\u001b[39mhead()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data.df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for FinTransformer:\n\tsize mismatch for encoder.characteristics_embeds.weight: copying a param with shape torch.Size([64, 94]) from checkpoint, the shape in current model is torch.Size([16, 94]).\n\tsize mismatch for encoder.characteristics_embeds.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for encoder.Transformer_Blocks.0.attention.vlinear.0.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.0.attention.vlinear.1.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.0.attention.vlinear.2.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.0.attention.vlinear.3.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.0.attention.vlinear.4.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.0.attention.vlinear.5.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.0.attention.vlinear.6.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.0.attention.vlinear.7.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.0.attention.klinear.0.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.0.attention.klinear.1.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.0.attention.klinear.2.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.0.attention.klinear.3.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.0.attention.klinear.4.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.0.attention.klinear.5.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.0.attention.klinear.6.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.0.attention.klinear.7.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.0.attention.qlinear.0.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.0.attention.qlinear.1.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.0.attention.qlinear.2.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.0.attention.qlinear.3.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.0.attention.qlinear.4.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.0.attention.qlinear.5.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.0.attention.qlinear.6.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.0.attention.qlinear.7.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.0.attention.feedforward.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for encoder.Transformer_Blocks.0.layernorm1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for encoder.Transformer_Blocks.0.layernorm1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for encoder.Transformer_Blocks.0.layernorm2.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for encoder.Transformer_Blocks.0.layernorm2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for encoder.Transformer_Blocks.0.feedforward.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for encoder.Transformer_Blocks.0.feedforward.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for encoder.Transformer_Blocks.0.feedforward.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for encoder.Transformer_Blocks.0.feedforward.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for encoder.Transformer_Blocks.1.attention.vlinear.0.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.1.attention.vlinear.1.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.1.attention.vlinear.2.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.1.attention.vlinear.3.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.1.attention.vlinear.4.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.1.attention.vlinear.5.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.1.attention.vlinear.6.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.1.attention.vlinear.7.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.1.attention.klinear.0.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.1.attention.klinear.1.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.1.attention.klinear.2.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.1.attention.klinear.3.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.1.attention.klinear.4.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.1.attention.klinear.5.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.1.attention.klinear.6.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.1.attention.klinear.7.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.1.attention.qlinear.0.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.1.attention.qlinear.1.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.1.attention.qlinear.2.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.1.attention.qlinear.3.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.1.attention.qlinear.4.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.1.attention.qlinear.5.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.1.attention.qlinear.6.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.1.attention.qlinear.7.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.1.attention.feedforward.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for encoder.Transformer_Blocks.1.layernorm1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for encoder.Transformer_Blocks.1.layernorm1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for encoder.Transformer_Blocks.1.layernorm2.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for encoder.Transformer_Blocks.1.layernorm2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for encoder.Transformer_Blocks.1.feedforward.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for encoder.Transformer_Blocks.1.feedforward.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for encoder.Transformer_Blocks.1.feedforward.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for encoder.Transformer_Blocks.1.feedforward.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for encoder.Transformer_Blocks.2.attention.vlinear.0.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.2.attention.vlinear.1.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.2.attention.vlinear.2.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.2.attention.vlinear.3.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.2.attention.vlinear.4.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.2.attention.vlinear.5.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.2.attention.vlinear.6.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.2.attention.vlinear.7.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.2.attention.klinear.0.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.2.attention.klinear.1.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.2.attention.klinear.2.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.2.attention.klinear.3.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.2.attention.klinear.4.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.2.attention.klinear.5.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.2.attention.klinear.6.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.2.attention.klinear.7.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.2.attention.qlinear.0.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.2.attention.qlinear.1.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.2.attention.qlinear.2.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.2.attention.qlinear.3.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.2.attention.qlinear.4.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.2.attention.qlinear.5.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.2.attention.qlinear.6.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.2.attention.qlinear.7.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.2.attention.feedforward.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for encoder.Transformer_Blocks.2.layernorm1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for encoder.Transformer_Blocks.2.layernorm1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for encoder.Transformer_Blocks.2.layernorm2.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for encoder.Transformer_Blocks.2.layernorm2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for encoder.Transformer_Blocks.2.feedforward.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for encoder.Transformer_Blocks.2.feedforward.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for encoder.Transformer_Blocks.2.feedforward.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for encoder.Transformer_Blocks.2.feedforward.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decoder.return_encoding.weight: copying a param with shape torch.Size([64, 1]) from checkpoint, the shape in current model is torch.Size([16, 1]).\n\tsize mismatch for decoder.return_encoding.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decoder.Decoder_Blocks.0.masked_attention.vlinear.0.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.masked_attention.vlinear.1.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.masked_attention.vlinear.2.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.masked_attention.vlinear.3.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.masked_attention.vlinear.4.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.masked_attention.vlinear.5.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.masked_attention.vlinear.6.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.masked_attention.vlinear.7.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.masked_attention.klinear.0.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.masked_attention.klinear.1.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.masked_attention.klinear.2.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.masked_attention.klinear.3.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.masked_attention.klinear.4.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.masked_attention.klinear.5.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.masked_attention.klinear.6.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.masked_attention.klinear.7.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.masked_attention.qlinear.0.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.masked_attention.qlinear.1.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.masked_attention.qlinear.2.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.masked_attention.qlinear.3.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.masked_attention.qlinear.4.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.masked_attention.qlinear.5.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.masked_attention.qlinear.6.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.masked_attention.qlinear.7.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.masked_attention.feedforward.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for decoder.Decoder_Blocks.0.layer_norm1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decoder.Decoder_Blocks.0.layer_norm1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decoder.Decoder_Blocks.0.encoder_decoder_attention.attention.vlinear.0.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.encoder_decoder_attention.attention.vlinear.1.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.encoder_decoder_attention.attention.vlinear.2.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.encoder_decoder_attention.attention.vlinear.3.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.encoder_decoder_attention.attention.vlinear.4.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.encoder_decoder_attention.attention.vlinear.5.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.encoder_decoder_attention.attention.vlinear.6.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.encoder_decoder_attention.attention.vlinear.7.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.encoder_decoder_attention.attention.klinear.0.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.encoder_decoder_attention.attention.klinear.1.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.encoder_decoder_attention.attention.klinear.2.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.encoder_decoder_attention.attention.klinear.3.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.encoder_decoder_attention.attention.klinear.4.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.encoder_decoder_attention.attention.klinear.5.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.encoder_decoder_attention.attention.klinear.6.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.encoder_decoder_attention.attention.klinear.7.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.encoder_decoder_attention.attention.qlinear.0.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.encoder_decoder_attention.attention.qlinear.1.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.encoder_decoder_attention.attention.qlinear.2.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.encoder_decoder_attention.attention.qlinear.3.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.encoder_decoder_attention.attention.qlinear.4.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.encoder_decoder_attention.attention.qlinear.5.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.encoder_decoder_attention.attention.qlinear.6.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.encoder_decoder_attention.attention.qlinear.7.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.encoder_decoder_attention.attention.feedforward.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for decoder.Decoder_Blocks.0.encoder_decoder_attention.layernorm1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decoder.Decoder_Blocks.0.encoder_decoder_attention.layernorm1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decoder.Decoder_Blocks.0.encoder_decoder_attention.layernorm2.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decoder.Decoder_Blocks.0.encoder_decoder_attention.layernorm2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decoder.Decoder_Blocks.0.encoder_decoder_attention.feedforward.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for decoder.Decoder_Blocks.0.encoder_decoder_attention.feedforward.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decoder.Decoder_Blocks.0.encoder_decoder_attention.feedforward.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for decoder.Decoder_Blocks.0.encoder_decoder_attention.feedforward.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decoder.Decoder_Blocks.1.masked_attention.vlinear.0.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.masked_attention.vlinear.1.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.masked_attention.vlinear.2.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.masked_attention.vlinear.3.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.masked_attention.vlinear.4.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.masked_attention.vlinear.5.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.masked_attention.vlinear.6.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.masked_attention.vlinear.7.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.masked_attention.klinear.0.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.masked_attention.klinear.1.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.masked_attention.klinear.2.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.masked_attention.klinear.3.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.masked_attention.klinear.4.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.masked_attention.klinear.5.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.masked_attention.klinear.6.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.masked_attention.klinear.7.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.masked_attention.qlinear.0.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.masked_attention.qlinear.1.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.masked_attention.qlinear.2.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.masked_attention.qlinear.3.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.masked_attention.qlinear.4.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.masked_attention.qlinear.5.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.masked_attention.qlinear.6.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.masked_attention.qlinear.7.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.masked_attention.feedforward.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for decoder.Decoder_Blocks.1.layer_norm1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decoder.Decoder_Blocks.1.layer_norm1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decoder.Decoder_Blocks.1.encoder_decoder_attention.attention.vlinear.0.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.encoder_decoder_attention.attention.vlinear.1.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.encoder_decoder_attention.attention.vlinear.2.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.encoder_decoder_attention.attention.vlinear.3.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.encoder_decoder_attention.attention.vlinear.4.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.encoder_decoder_attention.attention.vlinear.5.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.encoder_decoder_attention.attention.vlinear.6.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.encoder_decoder_attention.attention.vlinear.7.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.encoder_decoder_attention.attention.klinear.0.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.encoder_decoder_attention.attention.klinear.1.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.encoder_decoder_attention.attention.klinear.2.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.encoder_decoder_attention.attention.klinear.3.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.encoder_decoder_attention.attention.klinear.4.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.encoder_decoder_attention.attention.klinear.5.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.encoder_decoder_attention.attention.klinear.6.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.encoder_decoder_attention.attention.klinear.7.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.encoder_decoder_attention.attention.qlinear.0.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.encoder_decoder_attention.attention.qlinear.1.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.encoder_decoder_attention.attention.qlinear.2.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.encoder_decoder_attention.attention.qlinear.3.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.encoder_decoder_attention.attention.qlinear.4.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.encoder_decoder_attention.attention.qlinear.5.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.encoder_decoder_attention.attention.qlinear.6.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.encoder_decoder_attention.attention.qlinear.7.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.encoder_decoder_attention.attention.feedforward.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for decoder.Decoder_Blocks.1.encoder_decoder_attention.layernorm1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decoder.Decoder_Blocks.1.encoder_decoder_attention.layernorm1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decoder.Decoder_Blocks.1.encoder_decoder_attention.layernorm2.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decoder.Decoder_Blocks.1.encoder_decoder_attention.layernorm2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decoder.Decoder_Blocks.1.encoder_decoder_attention.feedforward.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for decoder.Decoder_Blocks.1.encoder_decoder_attention.feedforward.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decoder.Decoder_Blocks.1.encoder_decoder_attention.feedforward.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for decoder.Decoder_Blocks.1.encoder_decoder_attention.feedforward.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decoder.Decoder_Blocks.2.masked_attention.vlinear.0.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.masked_attention.vlinear.1.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.masked_attention.vlinear.2.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.masked_attention.vlinear.3.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.masked_attention.vlinear.4.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.masked_attention.vlinear.5.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.masked_attention.vlinear.6.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.masked_attention.vlinear.7.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.masked_attention.klinear.0.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.masked_attention.klinear.1.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.masked_attention.klinear.2.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.masked_attention.klinear.3.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.masked_attention.klinear.4.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.masked_attention.klinear.5.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.masked_attention.klinear.6.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.masked_attention.klinear.7.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.masked_attention.qlinear.0.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.masked_attention.qlinear.1.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.masked_attention.qlinear.2.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.masked_attention.qlinear.3.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.masked_attention.qlinear.4.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.masked_attention.qlinear.5.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.masked_attention.qlinear.6.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.masked_attention.qlinear.7.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.masked_attention.feedforward.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for decoder.Decoder_Blocks.2.layer_norm1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decoder.Decoder_Blocks.2.layer_norm1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decoder.Decoder_Blocks.2.encoder_decoder_attention.attention.vlinear.0.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.encoder_decoder_attention.attention.vlinear.1.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.encoder_decoder_attention.attention.vlinear.2.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.encoder_decoder_attention.attention.vlinear.3.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.encoder_decoder_attention.attention.vlinear.4.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.encoder_decoder_attention.attention.vlinear.5.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.encoder_decoder_attention.attention.vlinear.6.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.encoder_decoder_attention.attention.vlinear.7.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.encoder_decoder_attention.attention.klinear.0.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.encoder_decoder_attention.attention.klinear.1.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.encoder_decoder_attention.attention.klinear.2.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.encoder_decoder_attention.attention.klinear.3.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.encoder_decoder_attention.attention.klinear.4.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.encoder_decoder_attention.attention.klinear.5.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.encoder_decoder_attention.attention.klinear.6.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.encoder_decoder_attention.attention.klinear.7.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.encoder_decoder_attention.attention.qlinear.0.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.encoder_decoder_attention.attention.qlinear.1.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.encoder_decoder_attention.attention.qlinear.2.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.encoder_decoder_attention.attention.qlinear.3.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.encoder_decoder_attention.attention.qlinear.4.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.encoder_decoder_attention.attention.qlinear.5.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.encoder_decoder_attention.attention.qlinear.6.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.encoder_decoder_attention.attention.qlinear.7.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.encoder_decoder_attention.attention.feedforward.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for decoder.Decoder_Blocks.2.encoder_decoder_attention.layernorm1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decoder.Decoder_Blocks.2.encoder_decoder_attention.layernorm1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decoder.Decoder_Blocks.2.encoder_decoder_attention.layernorm2.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decoder.Decoder_Blocks.2.encoder_decoder_attention.layernorm2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decoder.Decoder_Blocks.2.encoder_decoder_attention.feedforward.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for decoder.Decoder_Blocks.2.encoder_decoder_attention.feedforward.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decoder.Decoder_Blocks.2.encoder_decoder_attention.feedforward.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for decoder.Decoder_Blocks.2.encoder_decoder_attention.feedforward.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decoder.final_linear_layer.weight: copying a param with shape torch.Size([1, 64]) from checkpoint, the shape in current model is torch.Size([1, 16]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32md:\\FinTransformers\\v1.1-prev\\predict.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/FinTransformers/v1.1-prev/predict.ipynb#W3sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m testloader \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(\u001b[39m\"\u001b[39m\u001b[39mtestloader.pt\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/FinTransformers/v1.1-prev/predict.ipynb#W3sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m test_model \u001b[39m=\u001b[39m FinTransformer(embed_size, inner_dim, num_companies, num_characteristics, heads, repeats, dropout)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/FinTransformers/v1.1-prev/predict.ipynb#W3sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m test_model\u001b[39m.\u001b[39;49mload_state_dict(torch\u001b[39m.\u001b[39;49mload(\u001b[39m\"\u001b[39;49m\u001b[39m./checkpoint/best_model.pt\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n",
      "File \u001b[1;32mc:\\Users\\sandi\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1671\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   1666\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[0;32m   1667\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   1668\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(k) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[0;32m   1670\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m-> 1671\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   1672\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[0;32m   1673\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for FinTransformer:\n\tsize mismatch for encoder.characteristics_embeds.weight: copying a param with shape torch.Size([64, 94]) from checkpoint, the shape in current model is torch.Size([16, 94]).\n\tsize mismatch for encoder.characteristics_embeds.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for encoder.Transformer_Blocks.0.attention.vlinear.0.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.0.attention.vlinear.1.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.0.attention.vlinear.2.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.0.attention.vlinear.3.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.0.attention.vlinear.4.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.0.attention.vlinear.5.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.0.attention.vlinear.6.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.0.attention.vlinear.7.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.0.attention.klinear.0.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.0.attention.klinear.1.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.0.attention.klinear.2.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.0.attention.klinear.3.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.0.attention.klinear.4.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.0.attention.klinear.5.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.0.attention.klinear.6.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.0.attention.klinear.7.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.0.attention.qlinear.0.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.0.attention.qlinear.1.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.0.attention.qlinear.2.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.0.attention.qlinear.3.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.0.attention.qlinear.4.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.0.attention.qlinear.5.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.0.attention.qlinear.6.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.0.attention.qlinear.7.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.0.attention.feedforward.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for encoder.Transformer_Blocks.0.layernorm1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for encoder.Transformer_Blocks.0.layernorm1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for encoder.Transformer_Blocks.0.layernorm2.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for encoder.Transformer_Blocks.0.layernorm2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for encoder.Transformer_Blocks.0.feedforward.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for encoder.Transformer_Blocks.0.feedforward.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for encoder.Transformer_Blocks.0.feedforward.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for encoder.Transformer_Blocks.0.feedforward.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for encoder.Transformer_Blocks.1.attention.vlinear.0.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.1.attention.vlinear.1.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.1.attention.vlinear.2.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.1.attention.vlinear.3.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.1.attention.vlinear.4.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.1.attention.vlinear.5.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.1.attention.vlinear.6.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.1.attention.vlinear.7.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.1.attention.klinear.0.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.1.attention.klinear.1.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.1.attention.klinear.2.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.1.attention.klinear.3.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.1.attention.klinear.4.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.1.attention.klinear.5.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.1.attention.klinear.6.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.1.attention.klinear.7.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.1.attention.qlinear.0.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.1.attention.qlinear.1.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.1.attention.qlinear.2.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.1.attention.qlinear.3.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.1.attention.qlinear.4.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.1.attention.qlinear.5.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.1.attention.qlinear.6.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.1.attention.qlinear.7.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.1.attention.feedforward.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for encoder.Transformer_Blocks.1.layernorm1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for encoder.Transformer_Blocks.1.layernorm1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for encoder.Transformer_Blocks.1.layernorm2.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for encoder.Transformer_Blocks.1.layernorm2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for encoder.Transformer_Blocks.1.feedforward.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for encoder.Transformer_Blocks.1.feedforward.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for encoder.Transformer_Blocks.1.feedforward.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for encoder.Transformer_Blocks.1.feedforward.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for encoder.Transformer_Blocks.2.attention.vlinear.0.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.2.attention.vlinear.1.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.2.attention.vlinear.2.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.2.attention.vlinear.3.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.2.attention.vlinear.4.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.2.attention.vlinear.5.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.2.attention.vlinear.6.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.2.attention.vlinear.7.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.2.attention.klinear.0.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.2.attention.klinear.1.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.2.attention.klinear.2.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.2.attention.klinear.3.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.2.attention.klinear.4.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.2.attention.klinear.5.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.2.attention.klinear.6.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.2.attention.klinear.7.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.2.attention.qlinear.0.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.2.attention.qlinear.1.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.2.attention.qlinear.2.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.2.attention.qlinear.3.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.2.attention.qlinear.4.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.2.attention.qlinear.5.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.2.attention.qlinear.6.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.2.attention.qlinear.7.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for encoder.Transformer_Blocks.2.attention.feedforward.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for encoder.Transformer_Blocks.2.layernorm1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for encoder.Transformer_Blocks.2.layernorm1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for encoder.Transformer_Blocks.2.layernorm2.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for encoder.Transformer_Blocks.2.layernorm2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for encoder.Transformer_Blocks.2.feedforward.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for encoder.Transformer_Blocks.2.feedforward.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for encoder.Transformer_Blocks.2.feedforward.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for encoder.Transformer_Blocks.2.feedforward.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decoder.return_encoding.weight: copying a param with shape torch.Size([64, 1]) from checkpoint, the shape in current model is torch.Size([16, 1]).\n\tsize mismatch for decoder.return_encoding.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decoder.Decoder_Blocks.0.masked_attention.vlinear.0.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.masked_attention.vlinear.1.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.masked_attention.vlinear.2.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.masked_attention.vlinear.3.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.masked_attention.vlinear.4.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.masked_attention.vlinear.5.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.masked_attention.vlinear.6.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.masked_attention.vlinear.7.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.masked_attention.klinear.0.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.masked_attention.klinear.1.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.masked_attention.klinear.2.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.masked_attention.klinear.3.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.masked_attention.klinear.4.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.masked_attention.klinear.5.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.masked_attention.klinear.6.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.masked_attention.klinear.7.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.masked_attention.qlinear.0.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.masked_attention.qlinear.1.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.masked_attention.qlinear.2.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.masked_attention.qlinear.3.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.masked_attention.qlinear.4.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.masked_attention.qlinear.5.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.masked_attention.qlinear.6.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.masked_attention.qlinear.7.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.masked_attention.feedforward.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for decoder.Decoder_Blocks.0.layer_norm1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decoder.Decoder_Blocks.0.layer_norm1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decoder.Decoder_Blocks.0.encoder_decoder_attention.attention.vlinear.0.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.encoder_decoder_attention.attention.vlinear.1.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.encoder_decoder_attention.attention.vlinear.2.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.encoder_decoder_attention.attention.vlinear.3.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.encoder_decoder_attention.attention.vlinear.4.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.encoder_decoder_attention.attention.vlinear.5.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.encoder_decoder_attention.attention.vlinear.6.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.encoder_decoder_attention.attention.vlinear.7.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.encoder_decoder_attention.attention.klinear.0.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.encoder_decoder_attention.attention.klinear.1.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.encoder_decoder_attention.attention.klinear.2.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.encoder_decoder_attention.attention.klinear.3.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.encoder_decoder_attention.attention.klinear.4.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.encoder_decoder_attention.attention.klinear.5.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.encoder_decoder_attention.attention.klinear.6.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.encoder_decoder_attention.attention.klinear.7.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.encoder_decoder_attention.attention.qlinear.0.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.encoder_decoder_attention.attention.qlinear.1.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.encoder_decoder_attention.attention.qlinear.2.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.encoder_decoder_attention.attention.qlinear.3.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.encoder_decoder_attention.attention.qlinear.4.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.encoder_decoder_attention.attention.qlinear.5.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.encoder_decoder_attention.attention.qlinear.6.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.encoder_decoder_attention.attention.qlinear.7.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.0.encoder_decoder_attention.attention.feedforward.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for decoder.Decoder_Blocks.0.encoder_decoder_attention.layernorm1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decoder.Decoder_Blocks.0.encoder_decoder_attention.layernorm1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decoder.Decoder_Blocks.0.encoder_decoder_attention.layernorm2.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decoder.Decoder_Blocks.0.encoder_decoder_attention.layernorm2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decoder.Decoder_Blocks.0.encoder_decoder_attention.feedforward.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for decoder.Decoder_Blocks.0.encoder_decoder_attention.feedforward.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decoder.Decoder_Blocks.0.encoder_decoder_attention.feedforward.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for decoder.Decoder_Blocks.0.encoder_decoder_attention.feedforward.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decoder.Decoder_Blocks.1.masked_attention.vlinear.0.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.masked_attention.vlinear.1.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.masked_attention.vlinear.2.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.masked_attention.vlinear.3.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.masked_attention.vlinear.4.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.masked_attention.vlinear.5.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.masked_attention.vlinear.6.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.masked_attention.vlinear.7.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.masked_attention.klinear.0.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.masked_attention.klinear.1.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.masked_attention.klinear.2.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.masked_attention.klinear.3.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.masked_attention.klinear.4.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.masked_attention.klinear.5.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.masked_attention.klinear.6.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.masked_attention.klinear.7.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.masked_attention.qlinear.0.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.masked_attention.qlinear.1.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.masked_attention.qlinear.2.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.masked_attention.qlinear.3.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.masked_attention.qlinear.4.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.masked_attention.qlinear.5.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.masked_attention.qlinear.6.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.masked_attention.qlinear.7.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.masked_attention.feedforward.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for decoder.Decoder_Blocks.1.layer_norm1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decoder.Decoder_Blocks.1.layer_norm1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decoder.Decoder_Blocks.1.encoder_decoder_attention.attention.vlinear.0.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.encoder_decoder_attention.attention.vlinear.1.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.encoder_decoder_attention.attention.vlinear.2.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.encoder_decoder_attention.attention.vlinear.3.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.encoder_decoder_attention.attention.vlinear.4.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.encoder_decoder_attention.attention.vlinear.5.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.encoder_decoder_attention.attention.vlinear.6.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.encoder_decoder_attention.attention.vlinear.7.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.encoder_decoder_attention.attention.klinear.0.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.encoder_decoder_attention.attention.klinear.1.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.encoder_decoder_attention.attention.klinear.2.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.encoder_decoder_attention.attention.klinear.3.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.encoder_decoder_attention.attention.klinear.4.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.encoder_decoder_attention.attention.klinear.5.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.encoder_decoder_attention.attention.klinear.6.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.encoder_decoder_attention.attention.klinear.7.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.encoder_decoder_attention.attention.qlinear.0.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.encoder_decoder_attention.attention.qlinear.1.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.encoder_decoder_attention.attention.qlinear.2.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.encoder_decoder_attention.attention.qlinear.3.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.encoder_decoder_attention.attention.qlinear.4.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.encoder_decoder_attention.attention.qlinear.5.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.encoder_decoder_attention.attention.qlinear.6.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.encoder_decoder_attention.attention.qlinear.7.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.1.encoder_decoder_attention.attention.feedforward.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for decoder.Decoder_Blocks.1.encoder_decoder_attention.layernorm1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decoder.Decoder_Blocks.1.encoder_decoder_attention.layernorm1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decoder.Decoder_Blocks.1.encoder_decoder_attention.layernorm2.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decoder.Decoder_Blocks.1.encoder_decoder_attention.layernorm2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decoder.Decoder_Blocks.1.encoder_decoder_attention.feedforward.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for decoder.Decoder_Blocks.1.encoder_decoder_attention.feedforward.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decoder.Decoder_Blocks.1.encoder_decoder_attention.feedforward.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for decoder.Decoder_Blocks.1.encoder_decoder_attention.feedforward.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decoder.Decoder_Blocks.2.masked_attention.vlinear.0.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.masked_attention.vlinear.1.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.masked_attention.vlinear.2.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.masked_attention.vlinear.3.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.masked_attention.vlinear.4.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.masked_attention.vlinear.5.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.masked_attention.vlinear.6.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.masked_attention.vlinear.7.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.masked_attention.klinear.0.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.masked_attention.klinear.1.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.masked_attention.klinear.2.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.masked_attention.klinear.3.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.masked_attention.klinear.4.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.masked_attention.klinear.5.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.masked_attention.klinear.6.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.masked_attention.klinear.7.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.masked_attention.qlinear.0.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.masked_attention.qlinear.1.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.masked_attention.qlinear.2.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.masked_attention.qlinear.3.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.masked_attention.qlinear.4.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.masked_attention.qlinear.5.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.masked_attention.qlinear.6.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.masked_attention.qlinear.7.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.masked_attention.feedforward.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for decoder.Decoder_Blocks.2.layer_norm1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decoder.Decoder_Blocks.2.layer_norm1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decoder.Decoder_Blocks.2.encoder_decoder_attention.attention.vlinear.0.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.encoder_decoder_attention.attention.vlinear.1.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.encoder_decoder_attention.attention.vlinear.2.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.encoder_decoder_attention.attention.vlinear.3.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.encoder_decoder_attention.attention.vlinear.4.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.encoder_decoder_attention.attention.vlinear.5.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.encoder_decoder_attention.attention.vlinear.6.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.encoder_decoder_attention.attention.vlinear.7.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.encoder_decoder_attention.attention.klinear.0.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.encoder_decoder_attention.attention.klinear.1.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.encoder_decoder_attention.attention.klinear.2.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.encoder_decoder_attention.attention.klinear.3.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.encoder_decoder_attention.attention.klinear.4.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.encoder_decoder_attention.attention.klinear.5.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.encoder_decoder_attention.attention.klinear.6.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.encoder_decoder_attention.attention.klinear.7.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.encoder_decoder_attention.attention.qlinear.0.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.encoder_decoder_attention.attention.qlinear.1.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.encoder_decoder_attention.attention.qlinear.2.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.encoder_decoder_attention.attention.qlinear.3.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.encoder_decoder_attention.attention.qlinear.4.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.encoder_decoder_attention.attention.qlinear.5.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.encoder_decoder_attention.attention.qlinear.6.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.encoder_decoder_attention.attention.qlinear.7.weight: copying a param with shape torch.Size([8, 8]) from checkpoint, the shape in current model is torch.Size([2, 2]).\n\tsize mismatch for decoder.Decoder_Blocks.2.encoder_decoder_attention.attention.feedforward.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for decoder.Decoder_Blocks.2.encoder_decoder_attention.layernorm1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decoder.Decoder_Blocks.2.encoder_decoder_attention.layernorm1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decoder.Decoder_Blocks.2.encoder_decoder_attention.layernorm2.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decoder.Decoder_Blocks.2.encoder_decoder_attention.layernorm2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decoder.Decoder_Blocks.2.encoder_decoder_attention.feedforward.0.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for decoder.Decoder_Blocks.2.encoder_decoder_attention.feedforward.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decoder.Decoder_Blocks.2.encoder_decoder_attention.feedforward.2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for decoder.Decoder_Blocks.2.encoder_decoder_attention.feedforward.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decoder.final_linear_layer.weight: copying a param with shape torch.Size([1, 64]) from checkpoint, the shape in current model is torch.Size([1, 16])."
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 512\n",
    "embed_size = 16\n",
    "inner_dim = 16\n",
    "num_characteristics = 94\n",
    "heads = 8\n",
    "repeats = 3\n",
    "dropout = 0.2\n",
    "batch_size = batch_size\n",
    "num_companies = batch_size\n",
    "\n",
    "testloader = torch.load(\"testloader.pt\")\n",
    "test_model = FinTransformer(embed_size, inner_dim, num_companies, num_characteristics, heads, repeats, dropout)\n",
    "test_model.load_state_dict(torch.load(\"./checkpoint/best_model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4916 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4916/4916 [02:47<00:00, 29.34it/s]\n"
     ]
    }
   ],
   "source": [
    "outputs = predict(model=test_model, testloader=testloader, num_companies=num_companies, num_characteristics=num_characteristics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, target = outputs[0], outputs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = torch.cat(output, dim = 0)\n",
    "target = torch.cat(target, dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(output, \"preds.pt\")\n",
    "torch.save(target, \"targets.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "testdata = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2516889, 97)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2516992])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.view(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['absacc', 'acc', 'age', 'agr', 'bm', 'bm_ia', 'cashdebt', 'cashpr',\n",
       "       'cfp', 'cfp_ia', 'chatoia', 'chcsho', 'chempia', 'chinv', 'chpmia',\n",
       "       'convind', 'currat', 'depr', 'divi', 'divo', 'dy', 'egr', 'ep', 'gma',\n",
       "       'grcapx', 'grltnoa', 'herf', 'hire', 'invest', 'lev', 'lgr', 'mve_ia',\n",
       "       'operprof', 'orgcap', 'pchcapx_ia', 'pchcurrat', 'pchdepr',\n",
       "       'pchgm_pchsale', 'pchquick', 'pchsale_pchinvt', 'pchsale_pchrect',\n",
       "       'pchsale_pchxsga', 'pchsaleinv', 'pctacc', 'ps', 'quick', 'rd',\n",
       "       'rd_mve', 'rd_sale', 'realestate', 'roic', 'salecash', 'saleinv',\n",
       "       'salerec', 'secured', 'securedind', 'sgr', 'sin', 'sp', 'tang', 'tb',\n",
       "       'aeavol', 'cash', 'chtx', 'cinvest', 'ear', 'ms', 'nincr', 'roaq',\n",
       "       'roavol', 'roeq', 'rsup', 'stdacc', 'stdcf', 'baspread', 'beta',\n",
       "       'betasq', 'chmom', 'dolvol', 'idiovol', 'ill', 'indmom', 'maxret',\n",
       "       'mom12m', 'mom1m', 'mom36m', 'mom6m', 'mvel1', 'pricedelay', 'retvol',\n",
       "       'std_dolvol', 'std_turn', 'turn', 'zerotrade', 'permno', 'month',\n",
       "       'ret-rf'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdata.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "testdata = pd.read_csv(\"FinalPredictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   -0.183182\n",
       "1    0.022790\n",
       "2   -0.106518\n",
       "3    2.085095\n",
       "4    0.036765\n",
       "5   -0.149913\n",
       "6    1.287183\n",
       "7   -0.327159\n",
       "8    2.206384\n",
       "9   -0.549023\n",
       "Name: ret-rf, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdata[\"ret-rf\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   -0.177973\n",
       "1    0.020929\n",
       "2   -0.104212\n",
       "3    2.074203\n",
       "4    0.034352\n",
       "5   -0.146083\n",
       "6    1.294620\n",
       "7   -0.313496\n",
       "8    2.200506\n",
       "9   -0.511939\n",
       "Name: predictions, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdata[\"predictions\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[-0.1831818   0.02278974 -0.10651751 ... -0.05556056 -1.0487953\n -0.26248229].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\FinTransformers\\v1\\predict.ipynb Cell 15\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/FinTransformers/v1/predict.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjoblib\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/FinTransformers/v1/predict.ipynb#X34sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m scaler \u001b[39m=\u001b[39m joblib\u001b[39m.\u001b[39mload(\u001b[39m\"\u001b[39m\u001b[39mReturnScaler.obj\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/FinTransformers/v1/predict.ipynb#X34sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m excess \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39;49minverse_transform(testdata[\u001b[39m\"\u001b[39;49m\u001b[39mret-rf\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/FinTransformers/v1/predict.ipynb#X34sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m excess_pred \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39minverse_transform(testdata[\u001b[39m\"\u001b[39m\u001b[39mpredictions\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\sandi\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:1034\u001b[0m, in \u001b[0;36mStandardScaler.inverse_transform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m   1031\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m   1033\u001b[0m copy \u001b[39m=\u001b[39m copy \u001b[39mif\u001b[39;00m copy \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy\n\u001b[1;32m-> 1034\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m   1035\u001b[0m     X,\n\u001b[0;32m   1036\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1037\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m   1038\u001b[0m     dtype\u001b[39m=\u001b[39;49mFLOAT_DTYPES,\n\u001b[0;32m   1039\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1040\u001b[0m )\n\u001b[0;32m   1042\u001b[0m \u001b[39mif\u001b[39;00m sparse\u001b[39m.\u001b[39missparse(X):\n\u001b[0;32m   1043\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwith_mean:\n",
      "File \u001b[1;32mc:\\Users\\sandi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:902\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    900\u001b[0m     \u001b[39m# If input is 1D raise error\u001b[39;00m\n\u001b[0;32m    901\u001b[0m     \u001b[39mif\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 902\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    903\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mExpected 2D array, got 1D array instead:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39marray=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    904\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    905\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    906\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mif it contains a single sample.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    907\u001b[0m         )\n\u001b[0;32m    909\u001b[0m \u001b[39mif\u001b[39;00m dtype_numeric \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39min\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mUSV\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    910\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    911\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdtype=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnumeric\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    912\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    913\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[-0.1831818   0.02278974 -0.10651751 ... -0.05556056 -1.0487953\n -0.26248229].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "scaler = joblib.load(\"ReturnScaler.obj\")\n",
    "excess = scaler.inverse_transform(testdata[\"ret-rf\"])\n",
    "excess_pred = scaler.inverse_transform(testdata[\"predictions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rets = np.array(testdata[\"ret-rf\"])\n",
    "excess = scaler.inverse_transform(rets.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.array(testdata[\"predictions\"])\n",
    "expr = scaler.inverse_transform(preds.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -2.36279328],\n",
       "       [  1.07017873],\n",
       "       [ -1.08970843],\n",
       "       [ 36.5089999 ],\n",
       "       [  1.30186493],\n",
       "       [ -1.8123953 ],\n",
       "       [ 23.05366213],\n",
       "       [ -4.70187743],\n",
       "       [ 38.68895089],\n",
       "       [ -8.12694139],\n",
       "       [-13.73357972],\n",
       "       [ -2.40378202],\n",
       "       [ 13.00977273],\n",
       "       [-29.78058908],\n",
       "       [  2.84906086],\n",
       "       [ 64.02821358],\n",
       "       [  8.13501013],\n",
       "       [ 11.5314973 ],\n",
       "       [ -6.86191479],\n",
       "       [ 45.80600197],\n",
       "       [  0.97138829],\n",
       "       [-15.06403625],\n",
       "       [ 11.2797164 ],\n",
       "       [ -0.42456915],\n",
       "       [ -3.15082161],\n",
       "       [ -2.2940559 ],\n",
       "       [ -9.06738613],\n",
       "       [  6.96786454],\n",
       "       [ -2.23608343],\n",
       "       [  2.88971422],\n",
       "       [ -8.02997083],\n",
       "       [ -1.06947279],\n",
       "       [  9.21335142],\n",
       "       [ -0.7904278 ],\n",
       "       [132.05617844],\n",
       "       [  1.69324496],\n",
       "       [ -3.1923597 ],\n",
       "       [  9.43832499],\n",
       "       [ -0.48083903],\n",
       "       [ -0.32277783],\n",
       "       [ -4.78493819],\n",
       "       [ -8.32343281],\n",
       "       [  1.97679488],\n",
       "       [  2.07525817],\n",
       "       [  4.09738663],\n",
       "       [ -9.33638635],\n",
       "       [ -1.17816809],\n",
       "       [ -7.58743229],\n",
       "       [-11.65579245],\n",
       "       [ 16.04138371],\n",
       "       [-11.97276872],\n",
       "       [  1.43131641],\n",
       "       [ -0.32277783],\n",
       "       [ 43.18593258],\n",
       "       [ 10.36798116],\n",
       "       [ 55.24518638],\n",
       "       [  1.29916753],\n",
       "       [ -1.08467678],\n",
       "       [  9.13149946],\n",
       "       [ -4.96078349],\n",
       "       [ -0.32277783],\n",
       "       [-11.97276872],\n",
       "       [ 17.48911126],\n",
       "       [ -6.32435055],\n",
       "       [  2.91129135],\n",
       "       [  3.5685699 ],\n",
       "       [ -4.70548734],\n",
       "       [ -2.64300797],\n",
       "       [ -7.1234699 ],\n",
       "       [  0.69624331],\n",
       "       [ -9.97545283],\n",
       "       [  3.00049892],\n",
       "       [ 20.27675269],\n",
       "       [  3.71110614],\n",
       "       [ -3.74496436],\n",
       "       [-17.55202464],\n",
       "       [-15.06403625],\n",
       "       [  3.53196573],\n",
       "       [ -0.91898221],\n",
       "       [ 11.67246777],\n",
       "       [ -5.87934556],\n",
       "       [  3.55777928],\n",
       "       [ 23.35895584],\n",
       "       [ -4.47014391],\n",
       "       [ -6.71670378],\n",
       "       [  8.13666437],\n",
       "       [ 32.87488547],\n",
       "       [  0.54316335],\n",
       "       [-14.6486399 ],\n",
       "       [ -1.05881899],\n",
       "       [ -1.8048    ],\n",
       "       [  3.9599201 ],\n",
       "       [  7.01221526],\n",
       "       [ 21.73824087],\n",
       "       [ 62.52765734],\n",
       "       [ -2.79308242],\n",
       "       [ 53.71717058],\n",
       "       [ 28.10353448],\n",
       "       [ -0.97501548],\n",
       "       [ 17.75086903]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expr[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -2.4527],\n",
       "       [  1.1023],\n",
       "       [ -1.1295],\n",
       "       [ 36.697 ],\n",
       "       [  1.3435],\n",
       "       [ -1.8785],\n",
       "       [ 22.9253],\n",
       "       [ -4.9377],\n",
       "       [ 38.7904],\n",
       "       [ -8.767 ],\n",
       "       [-14.1331],\n",
       "       [ -2.4956],\n",
       "       [ 13.1521],\n",
       "       [-28.9114],\n",
       "       [  2.9511],\n",
       "       [ 64.4748],\n",
       "       [  8.195 ],\n",
       "       [ 11.6258],\n",
       "       [ -7.3167],\n",
       "       [ 46.3267],\n",
       "       [  0.9994],\n",
       "       [-15.2336],\n",
       "       [ 11.3673],\n",
       "       [ -0.4445],\n",
       "       [ -3.2812],\n",
       "       [ -2.3808],\n",
       "       [ -9.8638],\n",
       "       [  7.0674],\n",
       "       [ -2.3202],\n",
       "       [  2.9933],\n",
       "       [ -8.6541],\n",
       "       [ -1.1086],\n",
       "       [  9.249 ],\n",
       "       [ -0.8208],\n",
       "       [125.9758],\n",
       "       [  1.7506],\n",
       "       [ -3.3251],\n",
       "       [  9.4782],\n",
       "       [ -0.5023],\n",
       "       [ -0.34  ],\n",
       "       [ -5.0275],\n",
       "       [ -8.9967],\n",
       "       [  2.0453],\n",
       "       [  2.1476],\n",
       "       [  4.2472],\n",
       "       [-10.1439],\n",
       "       [ -1.2209],\n",
       "       [ -8.1426],\n",
       "       [-12.6207],\n",
       "       [ 16.3267],\n",
       "       [-12.84  ],\n",
       "       [  1.4782],\n",
       "       [ -0.34  ],\n",
       "       [ 43.41  ],\n",
       "       [ 10.4292],\n",
       "       [ 57.0129],\n",
       "       [  1.3407],\n",
       "       [ -1.1243],\n",
       "       [  9.1657],\n",
       "       [ -5.218 ],\n",
       "       [ -0.34  ],\n",
       "       [-12.84  ],\n",
       "       [ 17.8418],\n",
       "       [ -6.715 ],\n",
       "       [  3.0157],\n",
       "       [  3.698 ],\n",
       "       [ -4.9416],\n",
       "       [ -2.7464],\n",
       "       [ -7.6127],\n",
       "       [  0.7126],\n",
       "       [-10.8187],\n",
       "       [  3.1083],\n",
       "       [ 20.4933],\n",
       "       [  3.846 ],\n",
       "       [ -3.9114],\n",
       "       [-17.4132],\n",
       "       [-15.2336],\n",
       "       [  3.66  ],\n",
       "       [ -0.9533],\n",
       "       [ 11.7707],\n",
       "       [ -6.2224],\n",
       "       [  3.6868],\n",
       "       [ 23.1968],\n",
       "       [ -4.6878],\n",
       "       [ -7.1532],\n",
       "       [  8.1966],\n",
       "       [ 32.9933],\n",
       "       [  0.5529],\n",
       "       [-14.8855],\n",
       "       [ -1.0976],\n",
       "       [ -1.8706],\n",
       "       [  4.1044],\n",
       "       [  7.1103],\n",
       "       [ 21.7653],\n",
       "       [ 63.1009],\n",
       "       [ -2.9041],\n",
       "       [ 55.3418],\n",
       "       [ 27.9717],\n",
       "       [ -1.0111],\n",
       "       [ 18.1184]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "excess[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
